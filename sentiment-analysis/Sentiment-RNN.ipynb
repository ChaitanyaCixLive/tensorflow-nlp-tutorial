{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Simple Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "# tf.reset_default_graph()\n",
    "session = tf.InteractiveSession()\n",
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sentence:', '@VirginAmerica Is flight 769 on it\\'s way? Was supposed to take off 30 minutes ago. Website still shows \"On Time\" not \"In Flight\". Thanks.')\n",
      "('Label:', 'neutral')\n"
     ]
    }
   ],
   "source": [
    "max_length = 50\n",
    "X, y, index_to_word, sentences = utils.load_sentiment_data(max_length)\n",
    "X_train, y_train, X_test, y_test = utils.split_data(X, y)\n",
    "vocab_size = len(index_to_word)\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "s_i = 50\n",
    "print(\"Sentence:\", sentences[s_i])\n",
    "print(\"Label:\", utils.label_to_desc(y[s_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_placeholder = tf.placeholder(tf.float32, shape=(None, max_length, vocab_size), name='data_placeholder')\n",
    "labels_placeholder = tf.placeholder(tf.float32, shape=(None, n_classes), name='labels_placeholder')\n",
    "keep_prob_placeholder = tf.placeholder(tf.float32, name='keep_prob_placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper function for fully connected layers\n",
    "\n",
    "def linear(input_, output_size, layer_scope, stddev=0.02, bias_start=0.0):\n",
    "    shape = input_.get_shape().as_list()\n",
    "\n",
    "    with tf.variable_scope(layer_scope):\n",
    "        matrix = tf.get_variable(\"Matrix\", [shape[1], output_size], tf.float32,\n",
    "                                 tf.random_normal_initializer(stddev=stddev))\n",
    "        bias = tf.get_variable(\"bias\", [output_size],\n",
    "            initializer=tf.constant_initializer(bias_start))\n",
    "        return tf.matmul(input_, matrix) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.LSTMCell object at 0x1164505d0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.LSTMCell object at 0x1164505d0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    }
   ],
   "source": [
    "# Define Computation Graph\n",
    "n_rnn_layers = 3\n",
    "n_fc_layers = 2\n",
    "n_rnn_nodes = 256\n",
    "n_fc_nodes = 128\n",
    "\n",
    "with tf.name_scope(\"recurrent_layers\") as scope:\n",
    "    # Create LSTM Cell\n",
    "    cell = tf.nn.rnn_cell.LSTMCell(n_rnn_nodes, state_is_tuple=False)\n",
    "    cell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "        cell, output_keep_prob=keep_prob_placeholder)\n",
    "    stacked_cells = tf.nn.rnn_cell.MultiRNNCell([cell] * n_rnn_layers, state_is_tuple=False)\n",
    "    output, encoding = tf.nn.dynamic_rnn(stacked_cells, data_placeholder, dtype=tf.float32)\n",
    "\n",
    "with tf.name_scope(\"fc_layers\") as scope:\n",
    "    # Connect RNN Embedding output into fully connected layers\n",
    "    prev_layer = encoding\n",
    "    for fc_index in range(0, n_fc_layers-1):\n",
    "        fci = tf.nn.relu(linear(prev_layer, n_fc_nodes, 'fc{}'.format(fc_index)))\n",
    "        fc_prev = fci\n",
    "\n",
    "    fc_final = linear(fc_prev, n_classes, 'fc{}'.format(n_fc_layers-1))\n",
    "\n",
    "logits = tf.nn.softmax(fc_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Loss Function + Optimizer\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, labels_placeholder))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.0002).minimize(loss)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "prediction_is_correct = tf.equal(\n",
    "    tf.argmax(logits, 1), tf.argmax(labels_placeholder, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction_is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch train loss at step 0 : 1.09861\n",
      "Minibatch train accuracy: 0.469%\n",
      "Test loss: 1.099\n",
      "Test accuracy: 0.468%\n",
      "Minibatch train loss at step 2 : 1.0986\n",
      "Minibatch train accuracy: 0.438%\n",
      "Test loss: 1.099\n",
      "Test accuracy: 0.431%\n",
      "Minibatch train loss at step 4 : 1.0986\n",
      "Minibatch train accuracy: 0.469%\n",
      "Test loss: 1.099\n",
      "Test accuracy: 0.483%\n",
      "Minibatch train loss at step 6 : 1.0986\n",
      "Minibatch train accuracy: 0.469%\n",
      "Test loss: 1.099\n",
      "Test accuracy: 0.565%\n",
      "Minibatch train loss at step 8 : 1.0986\n",
      "Minibatch train accuracy: 0.406%\n",
      "Test loss: 1.099\n",
      "Test accuracy: 0.567%\n",
      "Minibatch train loss at step 10 : 1.09859\n",
      "Minibatch train accuracy: 0.500%\n",
      "Test loss: 1.099\n",
      "Test accuracy: 0.557%\n",
      "Minibatch train loss at step 12 : 1.0986\n",
      "Minibatch train accuracy: 0.438%\n",
      "Test loss: 1.099\n",
      "Test accuracy: 0.542%\n",
      "Minibatch train loss at step 14 : 1.09862\n",
      "Minibatch train accuracy: 0.188%\n",
      "Test loss: 1.099\n",
      "Test accuracy: 0.506%\n",
      "Minibatch train loss at step"
     ]
    }
   ],
   "source": [
    "# Train loop\n",
    "\n",
    "num_steps = 1000\n",
    "batch_size = 32\n",
    "keep_prob_rate = 0.75\n",
    "\n",
    "tf.initialize_all_variables().run()\n",
    "\n",
    "for step in xrange(num_steps):\n",
    "    offset = (step * batch_size) % (X_train.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = X_train[offset:(offset + batch_size), :, :]\n",
    "    batch_labels = y_train[offset:(offset + batch_size), :]\n",
    "    # We built our networking using placeholders. It's like we've made reservations for a party of 6.\n",
    "    # So use feed_dict to fill what we reserved. And we can't show up with 9 people. \n",
    "\n",
    "    feed_dict_train = {data_placeholder: batch_data, labels_placeholder : batch_labels, keep_prob_placeholder: keep_prob_rate}\n",
    "    # Run the optimizer, get the loss, get the predictions.\n",
    "    # We can run multiple things at once and get their outputs\n",
    "    _, loss_value_train, predictions_value_train, accuracy_value_train = session.run(\n",
    "      [optimizer, loss, prediction, accuracy], feed_dict=feed_dict_train)\n",
    "    if (step % 2 == 0):\n",
    "        print \"Minibatch train loss at step\", step, \":\", loss_value_train\n",
    "        print \"Minibatch train accuracy: %.3f%%\" % accuracy_value_train\n",
    "        feed_dict_test = {data_placeholder: X_test, labels_placeholder: y_test, keep_prob_placeholder: 1.0}\n",
    "        loss_value_test, predictions_value_test, accuracy_value_test = session.run(\n",
    "            [loss, prediction, accuracy], feed_dict=feed_dict_test)\n",
    "        print \"Test loss: %.3f\" % loss_value_test\n",
    "        print \"Test accuracy: %.3f%%\" % accuracy_value_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
